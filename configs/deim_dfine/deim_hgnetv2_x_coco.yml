__include__: [
  './dfine_hgnetv2_x_coco.yml',
  '../base/deim.yml'
]

output_dir: ./outputs/deim_hgnetv2_x_coco
  
optimizer:
  type: AdamW
  params: 
    - 
      params: '^(?=.*backbone)(?!.*norm|bn).*$'
      lr: 0.0000025   
    - 
      params: '^(?=.*(?:encoder|decoder))(?=.*(?:norm|bn)).*$'
      weight_decay: 0.

  lr: 0.00025
  betas: [0.9, 0.999]
  weight_decay: 0.000125
  
# Increase to search for the optimal ema
epoches: 58 # 72 + 2n

## Our LR-Scheduler
flat_epoch: 29    # 4 + epoch // 2, e.g., 40 = 4 + 72 / 2
no_aug_epoch: 8

train_dataloader: 
  total_batch_size: 4 # 32
  dataset: 
    transforms:
      policy:
        epoch: 50

  collate_fn:
    # mixup_epochs: [4, 29]
    mixup_epochs: [161,162]
    stop_epoch: 50

val_dataloader:
  total_batch_size: 4